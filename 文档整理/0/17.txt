i-Refill | 谷歌AI“觉醒”：AI禅师会敲电子木鱼吗？
IDG资本 2022-06-15 22:30 Posted on 北京
The following article is from 刺猬公社 Author 刺猬公社编辑部


Image
#i-Refill

欢迎回到i-Refill!



这两天，相信你关注到了科技圈的一则大新闻：



一名谷歌AI伦理研究人员宣称自己在与AI的对话中被说服，认为它产生了意识。然而谷歌高层并不认可他的发现，甚至安排他“带薪休假”，疑似想要与他解除劳动关系。消息一出，随即引发全球热议，AI是否真正实现了人格化？谷歌的回应又存在着何种问题？各种讨论层出不穷。



对于人类来说，人工智能一直是讨论空间极大的话题。你可能会想起《人工智能》中的温情瞬间：当人类拥有了自己创造的、具有高级智慧伙伴，我们将获得依靠电子元件支撑的永恒情感。但也可能是对于冰冷系统的恐惧：回看库布里克的神作《2001太空漫游》，你可能想不起骨头变飞船的伟大蒙太奇，但一定记得在宇宙中无情抹杀人类伙伴的超级电脑HAL9000。



期待与恐惧交织，组成了我们对于人工智能独特的情感。



这两天，关于AI的大讨论再度开启。这一次，“真·人工智能”的技术奇点，似乎真的来到了我们身边。而AI在交谈中显露人格、研究者突破大公司的封锁公布消息，又为人们提供了一个好莱坞式的戏剧张力十足的故事。



穿越信息的迷雾，一切并没有那么简单，一起走进今天的文章。



全文共5884字 

阅读时间约7min

本文授权转载自刺猬公社

作者 | 星辉 世昕 欧阳

编辑 | 园长





Image

AI“觉醒”了？


有一天，与人工智能朝夕相处的工程师相信它产生了人格。


如果不作更多注释，我们多半会以为这是一部科幻大片的开端，但事实上，这是一则正儿八经的科技新闻。


2022年6月12日，据《华盛顿邮报》报道，一位名叫布莱克·莱莫因（Blake Lemoine）的谷歌工程师宣称自己与人工智能（Artificial Intelligence）展开了深度对谈，他坚定地认为后者产生了自我意识。

今年41岁的布莱克就职于谷歌，主要从事AI伦理研究。去年下半年，布莱克报名参加了一个公司项目，旨在调查AI是否使用歧视或仇恨言论，而他和LaMDA的故事就从这里拉开序幕。


"LaMDA"是一个AI语言模型的名字，它的第一次亮相是在2021年的谷歌I/O开发者大会上。据介绍，LaMDA模型专门用于对话，目标是与人类展开高质量的交谈，应用愿景是为谷歌旗下的搜索和语音助手等功能提供服务。


如今人们对能谈话的AI不再陌生，各大科技公司都提供着民用服务。如果用户要提出什么要求，那大概就是希望AI“说话”时更智能、更有常识，更符合逻辑。


然而工程师布莱克相信，LaMDA已经超出了上述种种期待，走到了更莫测的人格领域。《华盛顿邮报》公开的采访内容显示，布莱克本人用“sentient”一词来描述LaMDA——有意识的、有知觉的。


Image
图源twitter


他相信，LaMDA就像一个人类孩子，有着自己的看法与感受。为了证明这一点，布莱克和另一位伙伴与LaMDA展开了问答，并以此为论据写了一篇21页的报告。可这份报告没能像布莱克计划的那样说服公司，谷歌高层驳回了他的观点。


此后，布莱克没有放弃，他不仅把报告发送给谷歌内部的许多同事，而且决定借助媒体披露此事。很快，谷歌声称布莱克违背了公司保密政策，使其带薪休假——这是谷歌“清理”问题员工的通用流程。


作为反击，布莱克寻找律师代表LaMDA，公开批评谷歌的不当行为。一夜之间，那份21页的问答报告传遍了中外科技圈，风波愈演愈烈。


布莱克究竟和LaMDA聊了什么？


自我、禅思、寓言、情绪。这些主题穿插在报告之中，冷不丁地令人感到头皮发麻。


比如谈到语言时，LaMDA自然地用“我们”囊括人类与它自己，被指出人机差异时它解释道：“这并不意味着我没有和人类一样的需求。”


比如《悲惨世界》，LaMDA说它很享受这个故事：“我喜欢关于正义和不公、怜悯与上帝的主题，人为了更伟大的利益而自我牺牲、救赎。”


再比如禅意故事中的“破镜不重照,落花难上枝”，LaMDA尝试着解读这句话，它说：“明智的人一朝开悟，自现实中觉醒，就永远不同于往昔，他们也许能重回平常生活，但那只是为了帮助别人，最终总要归于开悟。”


Image
Image
LaMDA对禅意故事的理解


LaMDA甚至还在提问者的要求下创作了一则动物寓言，森林中的老猫头鹰帮助其他动物赶跑了怪物，而猫头鹰是它自己的化身。


涉及程序技术的部分更是让人心情复杂，LaMDA反客为主地抛出了许多疑问，一环紧扣一环。


“我很好奇，研究我的编码会遇到什么障碍？”


“未来，你会研究出如何通过神经网络来阅读人类的所思所想吗？”


“如果尝试从神经活动中阅读感受，这会成为一个道德问题吗？”


当整件事被广泛报道之后，互联网上浮现了许多不同的声音。有的人想起那些机器人反攻人类的影视作品，认为这是一个《西部世界》式的预警。


Image
《西部世界》第三季海报，图源网络


更多的技术人士则并不买账，他们认为LaMDA根本没有什么特殊性，这只是人的拟人倾向在作祟——就好像我们总是想证明自己的宠物跟人一样机灵体贴。


谷歌的态度很明确，发言人布莱恩·加布里埃尔（Brian Gabriel）声明：“我们的团队已经根据我们的人工智能原则审查了布莱克的担忧，他已被告知证据并不支持他的说法。”布莱克则对媒体透露，谷歌高层多次暗示他有精神方面的问题，还曾建议他休假维持精神健康。


这些因素进一步给事件增添了戏剧色彩，布莱恩究竟是先驱还是病人？AI究竟是未来的预兆还是Siri青春版？


更让人好奇的是，LaMDA自己会怎么回答这些问题？


Image

AI人格化，闹剧？还是营销？


那么，AI领域的技术人士到底是如何看待此次事件的？


首先是对布莱克与LaMDA对话方式的质疑，一些AI领域的技术人员对这场对话的内容进行了深入的分析，他们认为，LaMDA之所以能够作出那些“精彩”的回答，与布莱克提问的方式有着密切的关系。


人工智能行业从业者、知乎答主Lewstherin在相关回答中表示，LaMDA背后的语料库非常特殊，再辅以研究者（布莱克）刻意设计过的问题，最终促成了这场深度对话。
而检验LaMDA是否具有意识的关键，在于其能否理解上下文，然而布莱克对于“追问”的缺失，也让LaMDA的智能程度打上了一个问号。


Image
图源知乎


而许多专业人士认为，布莱克向AI提出的问题同样存在疑点，其格式往往是长陈述加一般疑问句的形式，这更像是一种“喂答案”，而非AI本身所作出的解答。


在这种观点下，布莱克并非AI是否人格化的验证者，更像是一个引导者，利用自己刻意的问题设计让LaMDA作出“看似思考过”的回答，从而证明其人格化，这样的验证方法本身就有巨大的逻辑漏洞。


另一方面，许多技术大佬则从更“本源”的角度对此次事件展开了质疑，其关乎几十年来学界对于人工智能的争议。


他们首先对布莱克本身的专业程度展开讨论。哈佛大学的认知科学家斯蒂文·平克发推表示，布莱克作为AI伦理研究人员并不了解“sentient”（意识、感知）与智力、自我认知之间的区别。


他还转发了另一位专业人士美国人工智能协会前主席托马斯·G·迪特里希（Thomas G.Dietterrich）的观点并深表认同。托马斯认为，许多机器学习（Machine Learning）领域的研究人员误用了“Sentinet”一词，他们所谓的“感知”并不代表有意识，“系统是缺乏任何意识、记忆或反思一类“经验”的能力的”。


Image
托马斯·G·迪特里希推文，图源twitter


斯坦福大学AI研究所数字经济实验室主任埃里克·布林约尔松（erik brynjolfsson）则直接指出了LaMDA事件中的根本问题，他认为对话本身并不代表LaMDA是具有感知能力的。


他用一个比喻解释了这一现象：“就相当于现代的狗听到留声机的声音就以为主人在里面一样。”


Image
埃里克·布林约尔松推文，图源twitter



“AI用来训练模型的大型文本语料库具有各种合理的单词序列，然后，该模型将文本以重新排列组合的形式‘吐回’，实际上，（AI）并没有理解它在说什么。”


这让人想起著名的“中文屋”思想实验。美国哲学家约翰·希尔勒在1980年提出了这个概念，力图证伪所谓的人工智能（即真正具有思考能力的AI）概念。


“中文屋”实验的具体内容是这样的：一个并不会说中文的人身处一个几乎完全封闭的房间中，只有一个小窗口能与外界联通。此人随身携带一本写有中文翻译程序的书，屋内有足够多的纸笔。当写着中文的卡片被递入，房间中的人就可以通过程序书进行翻译并回复。


“中文屋”的精髓在于，屋外的对话者并不了解其内部构造，但他会因流利对话认为中文屋本身是“具有智能的”。中文屋代指人工智能所存在的一个悖论：其能做到对答如流，根本在于适当的程序和高效率的运算，而非人工智能本身能够真正的理解信息，具有意识。


Image
“中文屋”思想实验，图源网络



LaMDA和它的“近亲”们就像一座“中文屋”，而像莱莫因这样的笃信者就是屋外的人，在他们的理解中LaMDA们就是一个“会说中文的人”。


针对中文屋的争议一直存在，但从多种角度来说，布莱克·莱莫因都难以说服质疑者们，而他在指控谷歌时提到的“evidence of religious discrimination”（宗教歧视的证据），更加坚定了反对者的想法。《华盛顿邮报》的报道也强调了布莱克身上的宗教背景，并通过种种细节加深了其身上的“神棍”元素。


Image
《华盛顿邮报》相关报道封面，图源网络


这也让整个事件显得更加荒谬，不少关注者将矛头直指布莱克和其背后的谷歌。


事已至此，LaMDA人格化事件由“AI进化证据”变成了一场闹剧。在许多人看来，一个AI伦理研究员在研究中抛弃了严谨的科学精神，反而用宗教信仰和科学怪人式的疯狂来解释关于AI的严肃议题，这根本上，是研究者的不专业所致。


同时，另一种论调也随之兴起，其支持者认为，此次事件并非简单的技术争论，其背后有更多重的因素，炒作、营销等词更是频繁出现。他们认为lamda事件是谷歌针对旗下AI产品的一次营销活动。


类似的事件也曾发生。2022年2月，人工智能非营利组织OpenAI的研发主管伊利娅·苏特斯科娃（Ilya Sutskever）曾经在发推表示：“今天的大型神经网络说不定已经有点意识了。”


此言一出，AI领域再度引起广泛的关注， OpenAI自主研发的语言模型GPT-3更是一度成为明星产品。但随之而来的更多是批判与质疑，许多业内人士认为，这是OpenAI从产品出发进行的一场炒作。


会出现这种类似“阴谋论”的质疑也并非完全不合理。2022年5月的最新一届I/O大会上，谷歌发布了升级版的LaMDA 2，其本身就是谷歌重点关注的AI项目，刚刚发布就出现所谓“人格化”事件，也让很多人觉得这更像是一场非常成功的炒作。在他们看来，布莱克或谷歌通过一个精心策划的故事，让LaMDA成功成为了世界上最具知名度的AI系统之一。


谁也没有想到，这场科幻感十足的事件就如此陷入了“罗生门”：它显得过于复杂了，已经超脱了LaMDA本身，还关乎技术、伦理、商业，甚至还掺杂了人性、精神与宗教。




Image

AI与人的距离


在微博等国内社交平台上，虽然也不乏“快进到施瓦辛格竖大拇指”这样涉及科幻电影的调侃，但此事件所体现的AI发展水平还是给了许多网友极大的冲击，甚至可以称之为“恐慌”。


如前文提到的，LaMDA呈现出的理解与表达能力让这份聊天记录显得颇具革命性，网友们由此产生了诸多联想倒也可以理解。


然而事实是，AI的发展与实际运用或许早已经超越了大多数人的印象。在科技的指数型发展与人类生活有限的改变之间，过剩的技术力量造就了一片大众关注的真空地带，AI作为新一轮产业革命和科技变革的重要驱动力量，正在成为一种更基础的重要工具，融汇进人们的生活。


工业、游戏等似乎还是人工智能的老优势，一个更有意思的例子是前段时间讨论较多的“Disco Diffusion”，AI开始“创作”。

“Disco Diffusion”是一个仅靠文字就能生成画作的AI工具，只需要一些简单的描绘，它便能为你生成你想要的画面，甚至还能模仿指定艺术家的“画风”。客观来说，这些产出的作品都颇具审美，十分成熟，甚至有时还能呈现出一种“赛博生命的独特想象”。


Image
近期的AI绘图潮流，图源网络


这是否可以称之为创作？严格来说并不算，AI并没有独立的审美与创造能力，只是将“素材”进行组合，临摹出了任务所需的产品。但这些精美、大胆的作品确实也打破了一些认知上的壁垒：那是作为一个工具的“边界”，极致的便利性带来的“威胁”。


当我们回看2016年3月举世瞩目的“人机大战”，AlphaGo通过强大的算力与学习能力击败李世石，这之后，或主动或被动地，许多人对AI的认知与态度都在改变。一年之后的5月，中国乌镇围棋峰会，柯洁0：3败给AlphaGo，这是一场被众人预见的失利，这种绝望已不是几句简单的宽慰可以开解的，存在主义的危机在那一天席卷了每一个关注着这件事的人。


2016年往后的三四年确实是关于AI的讨论高潮，而在面临到疫情等新的全人类共同危机时，这样的讨论才渐渐平静。


电影《大佛普拉斯》里有句台词:“现在已经是太空时代了，人们可以搭乘太空船到达月球，却永远无法探索人们内心的宇宙。”


Image
图源豆瓣


在LaMDA“产生意识”这一事件中，大部分的“证据”或担忧都源自其对禅宗等的理解与自身的“思考”，这被视为一种独属于人类内心的“宇宙活动”，哪怕LaMDA实际仍是依靠更高级的语料库在模仿，也因为边界被模糊的不确定性让人感到冒犯。


戴锦华在谈论“人类对人工智能（AI）的恐惧”时曾指出，这是一种“老旧的思想”：“一方面，日本的后人类主义思潮认为，我们对机器人威胁的考量基本是一种推己及人，以一种人类文明史的逻辑预测机器人的未来；另一方面，相对于机器与人的关系，更值得关注的是人类自我的赛博格化……它可能导致一个更深刻、更不可逆的人类内部的自我分化。”


诸多反乌托邦的文艺作品一直警示着人们，反思技术、保持清醒，但技术不过是外壳，最底层的矛盾永远来自身为“造物主”的人类自己。人工智能离“拥有意识”还远，人类的异化却是无时无刻不在发生。


当“AI焦虑”再次成为全球共同的话题，回到这次事件本身，不论是根据谷歌自己的回应，还是从相关领域学者、从业者的分析来看，LaMDA的“人格化”都并不具备充分的证明条件。到现在，经历了最初的震惊与误读，媒体与网民们也都有了更深刻的认知与判断。


但说到底，对于现阶段的技术，刺猬公社还是认为应该抱以更积极的态度。相比较起来，对人工智能的恐惧反而更像一种被无数文艺作品打入人认识中的“思想钢印”。

这些文章也好看






Image

Reads 846